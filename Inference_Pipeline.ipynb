{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04f7d1a0-5242-4cfd-91ab-a1d9a48bedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hopsworks_api_key = None  \n",
    "Arlanda = \"ARN\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "644762ee-3b32-4c43-aa6a-89bcb2ddc849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import joblib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51ace9e-cd3d-49bc-99cd-06a5ec1053fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hopsworks_connection():\n",
    "    project = hopsworks.login(api_key_value=hopsworks_api_key, host=\"eu-west.cloud.hopsworks.ai\")\n",
    "    fs = project.get_feature_store()\n",
    "    mr = project.get_model_registry()\n",
    "    return project, fs, mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0412f140-138d-4a87-83d7-d9005dce40b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(mr):\n",
    "    model = mr.get_model(name='flight_delay_predictor', version=1)\n",
    "    saved_model_dir = model.download()\n",
    "\n",
    "    model_pipeline = joblib.load(f\"{saved_model_dir}/model.pkl\")\n",
    "\n",
    "    with open(f\"{saved_model_dir}/metadata.json\", 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    print(f\"Training Accuracy: {metadata['accuracy']:.3f}\\n\")\n",
    "    print(f\"ROC-AUC score: {metadata['roc_auc']:.3f}\\n\")\n",
    "\n",
    "    return model_pipeline, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33b12b70-f8fc-42f8-bf2a-0f26cf2c1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch_data(fs, today, end_date):\n",
    "    flights_fg = fs.get_feature_group('flight_schedules', version=1)\n",
    "    temporal_fg = fs.get_feature_group('temporal_features', version=1)\n",
    "    weather_fg = fs.get_feature_group('weather_features', version=1)\n",
    "\n",
    "    today_str = today.strftime(\"%Y-%m-%d\")\n",
    "    end_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    df_flights = flights_fg.filter(\n",
    "        (flights_fg.scheduled_time >= today_str) & (flights_fg.scheduled_time < end_str)\n",
    "    ).read()\n",
    "\n",
    "    df_temporal = temporal_fg.filter(\n",
    "        (temporal_fg.date >= today_str) & (temporal_fg.date < end_str)\n",
    "    ).read()\n",
    "\n",
    "    df_weather = weather_fg.filter(\n",
    "        (weather_fg.timestamp >= today_str) & (weather_fg.timestamp < end_str)\n",
    "    ).read()\n",
    "\n",
    "    return df_flights, df_temporal, df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a90184-743e-42fe-80f3-e531a5c5d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df_flights, df_temporal, df_weather):\n",
    "    df_flights['date'] = pd.to_datetime(df_flights['scheduled_time']).dt.date.astype(str)\n",
    "    \n",
    "    batch_data = df_flights.merge(\n",
    "        df_temporal, left_on='date', right_on='date', how='left', suffixes=('', '_temporal')\n",
    "    )\n",
    "\n",
    "    batch_data['scheduled_hour'] = pd.to_datetime(batch_data['scheduled_time']).dt.floor('H')\n",
    "    df_weather['weather_hour'] = pd.to_datetime(df_weather['timestamp']).dt.floor('H')\n",
    "    \n",
    "    batch_data = batch_data.merge(\n",
    "        df_weather, \n",
    "        left_on=['arn_airport_role', 'scheduled_hour'], \n",
    "        right_on=['airport_code', 'weather_hour'], \n",
    "        how='left', \n",
    "        suffixes=('', '_weather')\n",
    "    )\n",
    "\n",
    "    batch_data['hour'] = pd.to_datetime(batch_data['scheduled_time']).dt.hour\n",
    "    batch_data['day_of_week'] = pd.to_datetime(batch_data['scheduled_time']).dt.dayofweek\n",
    "    batch_data['month'] = pd.to_datetime(batch_data['scheduled_time']).dt.month\n",
    "    \n",
    "    batch_data['time_of_day'] = pd.cut(\n",
    "        batch_data['hour'], \n",
    "        bins=[0, 6, 12, 18, 24], \n",
    "        labels=['night', 'morning', 'afternoon', 'evening'],\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "    weather_weights = {'clear': 0, 'fog': 2, 'rain': 1, 'rain_windy': 3, 'snow': 4, 'windy': 2}\n",
    "    batch_data['weather_impact'] = batch_data['weather_condition'].map(weather_weights).fillna(0)\n",
    "    \n",
    "    batch_data['high_wind'] = (batch_data['wind_speed'] > 15).astype(int)\n",
    "    batch_data['low_visibility'] = (batch_data['visibility'] < 5).astype(int)\n",
    "    batch_data['peak_international'] = (\n",
    "        batch_data['is_peak_travel'] & (batch_data['route_type'] == 'international')\n",
    "    ).astype(int)\n",
    "\n",
    "    for col in ['is_weekend', 'is_holiday', 'is_school_break', 'is_peak_travel', \n",
    "                'is_sportlov', 'is_summer_break', 'is_christmas_break']:\n",
    "        if col in batch_data.columns:\n",
    "            batch_data[col] = batch_data[col].fillna(False).astype(int)\n",
    "    \n",
    "    print(f\"Merged data shape: {batch_data.shape}\\n\")\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cf48a49-5fc5-4677-acd9-2d6f821f348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model_pipeline, metadata, batch_data):\n",
    "    categorical_features = metadata['categorical_features']\n",
    "    numerical_features = metadata['numerical_features']\n",
    "    all_features = categorical_features + numerical_features\n",
    "\n",
    "    X_batch = batch_data[all_features].copy()\n",
    "\n",
    "    for col in numerical_features:\n",
    "        if col in X_batch.columns:\n",
    "            X_batch[col] = X_batch[col].fillna(X_batch[col].median())\n",
    "\n",
    "    for col in categorical_features:\n",
    "        if col in X_batch.columns:\n",
    "            X_batch[col] = X_batch[col].fillna(\n",
    "                X_batch[col].mode()[0] if len(X_batch[col].mode()) > 0 else \"UNKNOWN\"\n",
    "            )\n",
    "\n",
    "    batch_data['delay_probability'] = model_pipeline.predict_proba(X_batch)[:,1]\n",
    "    batch_data['predicted_delayed'] = model_pipeline.predict(X_batch)\n",
    "\n",
    "    print(f\"Flights predicted as delayed: {batch_data['predicted_delayed'].sum()} / {len(batch_data)}\")\n",
    "    print(f\"Average delay probability: {batch_data['delay_probability'].mean():.2%}\\n\")\n",
    "    \n",
    "    # Preview high-risk flights\n",
    "    high_risk = batch_data.nlargest(10, 'delay_probability')[[\n",
    "        'flight_number', 'scheduled_time', 'route', 'weather_condition', \n",
    "        'delay_probability', 'predicted_delayed'\n",
    "    ]]\n",
    "    print(\"Top 10 flights at risk of delay:\")\n",
    "    print(high_risk)\n",
    "    print()\n",
    "    \n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "177f6fa4-e4f7-42f2-8c1e-ea4df59981f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(fs, batch_data, today):\n",
    "    base_columns = ['flight_id', 'flight_number', 'scheduled_time', 'route', \n",
    "                    'flight_direction', 'route_type', 'delay_probability', 'predicted_delayed']\n",
    "    \n",
    "    if 'weather_condition' in batch_data.columns and batch_data['weather_condition'].notna().any():\n",
    "        base_columns.append('weather_condition')\n",
    "    \n",
    "    monitoring_data = batch_data[base_columns].copy()\n",
    "    \n",
    "    if 'weather_condition' in monitoring_data.columns:\n",
    "        monitoring_data['weather_condition'] = monitoring_data['weather_condition'].fillna('unknown')\n",
    "    \n",
    "    monitoring_data['prediction_date'] = today.strftime('%Y-%m-%d')\n",
    "    monitoring_data['days_before_flight'] = (\n",
    "        pd.to_datetime(monitoring_data['scheduled_time']).dt.date - today.date()\n",
    "    ).apply(lambda x: x.days)\n",
    "    \n",
    "    monitoring_data['scheduled_time'] = pd.to_datetime(monitoring_data['scheduled_time'])\n",
    "    \n",
    "    monitor_fg = fs.get_or_create_feature_group(\n",
    "        name='flight_delay_predictions',\n",
    "        description='Flight delay prediction monitoring for Arlanda Airport',\n",
    "        version=1,\n",
    "        primary_key=['flight_id', 'prediction_date'],\n",
    "        event_time='scheduled_time'\n",
    "    )\n",
    "    \n",
    "    # Insert predictions\n",
    "    monitor_fg.insert(monitoring_data, wait=True)\n",
    "    \n",
    "    return monitor_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca36102f-1e97-4776-80cf-442c64bfecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forecast_dashboard(batch_data, today):\n",
    "    daily_forecast = batch_data.groupby(\n",
    "        pd.to_datetime(batch_data['scheduled_time']).dt.date\n",
    "    ).agg({\n",
    "        'flight_id': 'count',\n",
    "        'predicted_delayed': 'sum',\n",
    "        'delay_probability': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    daily_forecast.columns = ['date', 'total_flights', 'predicted_delays', 'avg_delay_prob']\n",
    "    daily_forecast['delay_rate'] = daily_forecast['predicted_delays'] / daily_forecast['total_flights']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    ax1 = axes[0]\n",
    "    ax1.bar(daily_forecast['date'], daily_forecast['predicted_delays'], \n",
    "            alpha=0.7, color='orange', label='Predicted Delays')\n",
    "    ax1.plot(daily_forecast['date'], daily_forecast['total_flights'], \n",
    "             marker='o', color='blue', linewidth=2, label='Total Flights')\n",
    "    ax1.set_xlabel('Date', fontsize=12)\n",
    "    ax1.set_ylabel('Number of Flights', fontsize=12)\n",
    "    ax1.set_title('Flight Delay Forecast - Arlanda Airport (Next 7 Days)', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(daily_forecast['date'], daily_forecast['avg_delay_prob'] * 100, \n",
    "             marker='s', color='red', linewidth=2.5, markersize=8)\n",
    "    ax2.fill_between(daily_forecast['date'], 0, daily_forecast['avg_delay_prob'] * 100, \n",
    "                     alpha=0.3, color='red')\n",
    "    ax2.set_xlabel('Date', fontsize=12)\n",
    "    ax2.set_ylabel('Average Delay Probability (%)', fontsize=12)\n",
    "    ax2.set_title('Daily Average Delay Risk', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    forecast_path = './flight_delay_forecast.png'\n",
    "    plt.savefig(forecast_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return forecast_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0edc849-5aa2-4583-9833-a0ec5704143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hindcast_dashboard(fs, monitor_fg, flights_fg, today):\n",
    "    \"\"\"Generate hindcast comparing predictions with actual outcomes.\"\"\"    \n",
    "    # Fetch historical predictions (from past 30 days)\n",
    "    past_date = (today - timedelta(days=30)).strftime('%Y-%m-%d')\n",
    "    historical_predictions = monitor_fg.filter(\n",
    "        monitor_fg.prediction_date >= past_date\n",
    "    ).read()\n",
    "    \n",
    "    if len(historical_predictions) == 0:\n",
    "        print(\"No historical predictions yet. Hindcast will be available after a few days.\\n\")\n",
    "        return None\n",
    "    \n",
    "    actual_outcomes = flights_fg.filter(\n",
    "        flights_fg.scheduled_time >= past_date\n",
    "    ).read()[['flight_id', 'is_delayed', 'delay_minutes']]\n",
    "    \n",
    "    hindcast_df = historical_predictions.merge(\n",
    "        actual_outcomes, on='flight_id', how='inner'\n",
    "    )\n",
    "    \n",
    "    if len(hindcast_df) == 0:\n",
    "        print(\"No matched predictions and outcomes yet.\\n\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Hindcast data: {len(hindcast_df)} flights with both predictions and outcomes\")\n",
    "    \n",
    "    accuracy = accuracy_score(hindcast_df['is_delayed'], hindcast_df['predicted_delayed'])\n",
    "    precision = precision_score(hindcast_df['is_delayed'], hindcast_df['predicted_delayed'])\n",
    "    recall = recall_score(hindcast_df['is_delayed'], hindcast_df['predicted_delayed'])\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(hindcast_df['is_delayed'], hindcast_df['predicted_delayed'])\n",
    "    \n",
    "    # Plot hindcast dashboard\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Confusion Matrix\n",
    "    ax1 = axes[0]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "                xticklabels=['On-Time', 'Delayed'],\n",
    "                yticklabels=['On-Time', 'Delayed'])\n",
    "    ax1.set_ylabel('Actual', fontsize=12)\n",
    "    ax1.set_xlabel('Predicted', fontsize=12)\n",
    "    ax1.set_title('Confusion Matrix - Model Performance', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Metrics\n",
    "    ax2 = axes[1]\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall']\n",
    "    values = [accuracy, precision, recall]\n",
    "    colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "    \n",
    "    bars = ax2.barh(metrics, values, color=colors, alpha=0.7)\n",
    "    ax2.set_xlim([0, 1])\n",
    "    ax2.set_xlabel('Score', fontsize=12)\n",
    "    ax2.set_title('Model Performance Metrics', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, value) in enumerate(zip(bars, values)):\n",
    "        ax2.text(value + 0.02, i, f'{value:.2%}', va='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    hindcast_path = './flight_delay_hindcast.png'\n",
    "    plt.savefig(hindcast_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\nModel Performance Summary:\")\n",
    "    print(f\"   Accuracy:  {accuracy:.2%}\")\n",
    "    print(f\"   Precision: {precision:.2%}\")\n",
    "    print(f\"   Recall:    {recall:.2%}\\n\")\n",
    "    \n",
    "    return hindcast_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f79d8832-e74d-426f-ac7b-85d6b287fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dashboards(project, forecast_path, hindcast_path, today):\n",
    "    dataset_api = project.get_dataset_api()\n",
    "    str_today = today.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if dataset_api.exists(\"Resources/flight_delays\") == False:\n",
    "        dataset_api.mkdir(\"Resources/flight_delays\")\n",
    "    \n",
    "    dataset_api.upload(\n",
    "        forecast_path, \n",
    "        f\"Resources/flight_delays/forecast_{str_today}.png\", \n",
    "        overwrite=True\n",
    "    )\n",
    "    \n",
    "    if hindcast_path:\n",
    "        dataset_api.upload(\n",
    "            hindcast_path, \n",
    "            f\"Resources/flight_delays/hindcast_{str_today}.png\", \n",
    "            overwrite=True\n",
    "        )\n",
    "    \n",
    "    print(f\"Dashboards uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0437588f-b517-43d3-bf4e-181debfe6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define prediction window\n",
    "    today = datetime.now()\n",
    "    forecast_days = 7\n",
    "    end_date = today + timedelta(days=forecast_days)\n",
    "    \n",
    "    # 1. Connect to Hopsworks\n",
    "    project, fs, mr = hopsworks_connection()\n",
    "    \n",
    "    # 2. Download model\n",
    "    model_pipeline, metadata = download_model(mr)\n",
    "    \n",
    "    # 3. Fetch batch data\n",
    "    df_flights, df_temporal, df_weather = fetch_batch_data(fs, today, end_date)\n",
    "    \n",
    "    # 4. Engineer features\n",
    "    batch_data = engineer_features(df_flights, df_temporal, df_weather)\n",
    "    \n",
    "    # 5. Make predictions\n",
    "    batch_data = make_predictions(model_pipeline, metadata, batch_data)\n",
    "    \n",
    "    # 6. Save predictions\n",
    "    monitor_fg = save_predictions(fs, batch_data, today)\n",
    "    \n",
    "    # 7. Generate forecast dashboard\n",
    "    forecast_path = generate_forecast_dashboard(batch_data, today)\n",
    "    \n",
    "    # 8. Generate hindcast dashboard\n",
    "    flights_fg = fs.get_feature_group('flight_schedules', version=1)\n",
    "    hindcast_path = generate_hindcast_dashboard(fs, monitor_fg, flights_fg, today)\n",
    "    \n",
    "    # 9. Upload dashboards\n",
    "    upload_dashboards(project, forecast_path, hindcast_path, today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b092034-d2f2-4dec-b3ca-219f8a687bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-06 17:15:48,305 INFO: Closing external client and cleaning up certificates.\n",
      "2026-01-06 17:15:48,309 INFO: Connection closed.\n",
      "2026-01-06 17:15:48,312 INFO: Initializing external client\n",
      "2026-01-06 17:15:48,313 INFO: Base URL: https://eu-west.cloud.hopsworks.ai:443\n",
      "2026-01-06 17:15:49,228 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://eu-west.cloud.hopsworks.ai:443/p/3207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100.000%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 578249/578249 elapsed<00:00 remaining<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 1 files)... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100.000%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 916/916 elapsed<00:00 remaining<00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.593ct (0 dirs, 2 files)... DONE\n",
      "\n",
      "ROC-AUC score: 0.573\n",
      "\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.68s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.23s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.27s) \n",
      "Merged data shape: (3568, 52)\n",
      "\n",
      "Flights predicted as delayed: 1871 / 3568\n",
      "Average delay probability: 50.97%\n",
      "\n",
      "Top 10 flights at risk of delay:\n",
      "     flight_number       scheduled_time  ... delay_probability predicted_delayed\n",
      "497          SK535  2026-01-06 07:55:00  ...          0.842883                 1\n",
      "105          FR881  2026-01-06 08:25:00  ...          0.836727                 1\n",
      "659          JU382  2026-01-07 18:50:00  ...          0.833674                 1\n",
      "1807         JU380  2026-01-06 08:10:00  ...          0.832592                 1\n",
      "3194        BLX165  2026-01-06 06:35:00  ...          0.824489                 1\n",
      "358         FR4616  2026-01-06 07:00:00  ...          0.822690                 1\n",
      "1466         FR312  2026-01-08 08:30:00  ...          0.813072                 1\n",
      "1898       FR4616A  2026-01-06 06:55:00  ...          0.806169                 1\n",
      "2159         FR312  2026-01-09 07:55:00  ...          0.806153                 1\n",
      "2924         HP781  2026-01-06 15:50:00  ...          0.805618                 1\n",
      "\n",
      "[10 rows x 6 columns]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://eu-west.cloud.hopsworks.ai:443/p/3207/fs/3151/fg/3347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |███████████████████████████████████████████████████████████████████████████████████| Rows 3568/3568 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: flight_delay_predictions_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://eu-west.cloud.hopsworks.ai:443/p/3207/jobs/named/flight_delay_predictions_1_offline_fg_materialization/executions\n",
      "2026-01-06 17:16:15,455 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2026-01-06 17:16:21,679 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-06 17:18:51,110 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2026-01-06 17:18:51,213 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-06 17:18:59,600 INFO: Execution finished successfully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.46s) \n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (3.34s) \n",
      "Hindcast data: 3568 flights with both predictions and outcomes\n",
      "\n",
      "Model Performance Summary:\n",
      "   Accuracy:  47.70%\n",
      "   Precision: 0.27%\n",
      "   Recall:    100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading /Users/unilangsachin/Desktop/ID2223-Scalable_ML/Flight-Delay-Tracker/./flight_delay_forecast.png: 100.000%|█████████████| 283667/283667 elapsed<00:03 remaining<00:00\n",
      "Uploading /Users/unilangsachin/Desktop/ID2223-Scalable_ML/Flight-Delay-Tracker/./flight_delay_hindcast.png: 100.000%|█████████████| 156742/156742 elapsed<00:02 remaining<00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboards uploaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Flight_Tracker)",
   "language": "python",
   "name": "flight-tracker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
